{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, LeakyReLU, Dropout, Input, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crossover = 1\n",
    "p_mutation = 0.3\n",
    "pop = 100\n",
    "gen = 20\n",
    "n_factors = 84 #retrieve from size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(\"final_data.csv\", index_col = [\"ticker\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = []\n",
    "for i in range(pop):\n",
    "    i = np.random.choice([0, 1], size=(n_factors,), p=[1./3, 2./3])\n",
    "    parents.append(i)\n",
    "\n",
    "parents = np.array(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(p1, p2): \n",
    "  \n",
    "   # converting the string to list for performing the crossover \n",
    "    l = list(p1) \n",
    "    q = list(p2) \n",
    "  \n",
    "    # generating the random number to perform crossover \n",
    "    k = random.randint(0, len(l)) \n",
    "  \n",
    "    # interchanging the genes \n",
    "    for i in range(k, len(l)): \n",
    "        l[i], q[i] = q[i], l[i] \n",
    "     \n",
    "    return np.array(l), np.array(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(c1, p_mutation = 0.3):\n",
    "    flag = np.random.rand(*c1.shape) <= p_mutation\n",
    "    ind = np.argwhere(flag)\n",
    "    for i in ind:\n",
    "        if c1[i] == 0:\n",
    "            c1[i] = 1\n",
    "        else:\n",
    "            c1[i] = 0\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(p):\n",
    "    c = np.cumsum(p)\n",
    "    r = sum(p)*np.random.rand()\n",
    "    ind = np.argwhere(r <= c)\n",
    "    return ind[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(X, gene):\n",
    "    feature_index = []\n",
    "    for i in range(len(gene)):\n",
    "        if gene[i] == 1:\n",
    "            feature_index.append(i)\n",
    "    df_filter = X[:, feature_index]\n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last(data, target):\n",
    "    last = {}\n",
    "    tickers = set(data.index.get_level_values(0))\n",
    "    for tic in sorted(tickers):\n",
    "        l = (data.loc[tic][-1:].drop(target, axis = 1)).to_dict(orient = \"list\")\n",
    "        last[tic] = l\n",
    "    last = pd.DataFrame(last).transpose()\n",
    "    for col in last.columns:\n",
    "        last[col] = last[col].str[0]\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fixer(DF, target):\n",
    "    last = get_last(DF, target)\n",
    "    DF = DF.replace([np.inf, -np.inf], np.nan)\n",
    "    DF = DF.dropna()\n",
    "    X = DF.drop([target], axis = 1)\n",
    "    y = DF[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):  #define the mean percentage error\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "    return np.mean((np.abs(y_true - y_pred)) / y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train, X_test, y_train, y_test, gene, dropout = 0.2, kernel_size = 2, batch_size = 512, epochs = 2, verbose = 0):\n",
    "    X_filt= feature_select(X_train, gene)\n",
    "    X_test_filt= feature_select(X_test, gene)\n",
    "    X_filt = np.expand_dims(X_filt, axis=2)\n",
    "    X_test_filt = np.expand_dims(X_test_filt, axis=2)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size, padding = \"causal\", input_shape = X_filt.shape[1:]))\n",
    "    model.add(LeakyReLU(alpha = 0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size, padding = \"causal\",  dilation_rate = 2))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size, padding = \"causal\", activation = \"relu\", dilation_rate = 3))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation = \"relu\"))\n",
    "    \n",
    "    model.compile(loss= \"mean_squared_error\", optimizer= \"adam\")\n",
    "    \n",
    "    model.fit(x=X_filt, y=y_train, batch_size = batch_size, epochs=epochs, validation_data=(X_test_filt, y_test), verbose=verbose)\n",
    "    \n",
    "    pred = model.predict(X_test_filt)\n",
    "    perc_err = mean_absolute_percentage_error(y_test, pred)\n",
    "    score = (100 - perc_err)/100\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##select one of the parents with roulette, one random\n",
    "#add switching of chromosomes in crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_fixer(DF, \"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 464640 samples, validate on 116161 samples\n",
      "Epoch 1/2\n",
      "464640/464640 [==============================] - 87s 187us/sample - loss: 428.4941 - val_loss: 98.8709\n",
      "Epoch 2/2\n",
      "464640/464640 [==============================] - 76s 163us/sample - loss: 80.9451 - val_loss: 20.2247\n"
     ]
    }
   ],
   "source": [
    "score_1 = evaluate(X_train, X_test, y_train, y_test, parents[0], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590517130415668"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {0:score_1, 1: score_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = evaluate(X_train, X_test, y_train, y_test, parents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [score_1, score_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = reproduction([parents[0], parents[1]], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for _ in range(100):\n",
    "    s.append(roulette_wheel_selection(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_eval(pop, X_train, X_test, y_train, y_test, dropout = 0.2, kernel_size = 2, batch_size = 512, epochs = 2, verbose = 0):\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    best_set = []\n",
    "    for i in range(len(pop)):\n",
    "        score = evaluate(X_train, X_test, y_train, y_test, pop[i], dropout = dropout, kernel_size = kernel_size, batch_size = batch_size, epochs = epochs, verbose = verbose) \n",
    "        scores.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_set = parents[i]\n",
    "    scores = np.array(scores)\n",
    "    return scores, best_score, best_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduction(pop, scores):\n",
    "    children = []\n",
    "    for _ in range(int(len(pop)/2)):\n",
    "        p_1 = pop[roulette_wheel_selection(scores)]\n",
    "        p_2 = random.choice(pop)\n",
    "        c_1, c_2 = crossover(p_1, p_2)\n",
    "        c_1, c_2 = mutation(c_1), mutation(c_2)\n",
    "        children.append(c_1)\n",
    "        children.append(c_2)\n",
    "    children = np.array(children)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 464640 samples, validate on 116161 samples\n",
      "Epoch 1/2\n",
      "464640/464640 [==============================] - 74s 160us/sample - loss: 640.8959 - val_loss: 136.4920\n",
      "Epoch 2/2\n",
      "464640/464640 [==============================] - 100s 215us/sample - loss: 75.2340 - val_loss: 19.8586\n",
      "Train on 464640 samples, validate on 116161 samples\n",
      "Epoch 1/2\n",
      "464640/464640 [==============================] - 96s 206us/sample - loss: 456.1621 - val_loss: 62.5211\n",
      "Epoch 2/2\n",
      "464640/464640 [==============================] - 86s 185us/sample - loss: 86.8197 - val_loss: 169.0995\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_set = []\n",
    "for i in range(2):\n",
    "    score = evaluate(X_train, X_test, y_train, y_test, parents[i], dropout = 0.2, kernel_size = 2, batch_size = 512, epochs = 2, verbose = 1)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_set = parents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA(X_train, X_test, y_train, y_test, dropout = 0.2, kernel_size = 2, batch_size = 512, epochs = 2, verbose = 0, p_mutation = 0.3, pop = 100, gen = 20, n_factors = 84):\n",
    "    parents = []\n",
    "    for i in range(pop):\n",
    "        i = np.random.choice([0, 1], size=(n_factors,), p=[1./3, 2./3])\n",
    "        parents.append(i)\n",
    "    parents = np.array(parents) \n",
    "    \n",
    "    best_score = 0\n",
    "    best_set = []\n",
    "    for i in range(gen):\n",
    "        scores, gen_best_score, gen_best_set = generation_eval(parents, X_train, X_test, y_train, y_test, dropout = dropout, kernel_size = kernel_size, \n",
    "                                                   batch_size = batch_size, epochs = epochs, verbose = verbose)\n",
    "        if gen_best_score > best_score:\n",
    "            best_score = gen_best_score\n",
    "            best_set = gen_best_set\n",
    "            print(f\"Best score gen {i+1}: {best_score}\")\n",
    "        \n",
    "        children = reproduction(parents, scores)\n",
    "        parents = children\n",
    "        \n",
    "    return best_score, best_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score gen 0: 0.7683118119827279\n",
      "Best score gen 1: 0.8632192308268318\n"
     ]
    }
   ],
   "source": [
    "best_score, best_set = GA(X_train, X_test, y_train, y_test, pop = 10, gen = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
